{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pankajmanisahu/Python-Assignments-and-Competitive-Coding-Solutions/blob/main/Assignment_Functions_%26_Methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq5jjKHb-zdZ"
      },
      "source": [
        "# <u> Problem 1</u>\n",
        "\n",
        "### Write a function which takes the excel column name as an input and returns the corresponding column number. A few examples are :\n",
        "\n",
        "* column name = <code>'J'</code> , column number = <code>10</code>\n",
        "* column name = <code>'AP'</code> , column number = <code>42</code>\n",
        "* column name = <code>'AAA'</code>, column number = <code>703</code>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un0QXOa3-zdb",
        "outputId": "685bcf49-b36f-4a35-c000-7380472329ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install openpyxl\n",
        "import openpyxl\n",
        "\n",
        "def get_excel_column_number(column_name):\n",
        "  '''\n",
        "  This functions returns the corresponding column number for an excel column name\n",
        "  '''\n",
        "  result = 0\n",
        "  for char in column_name:\n",
        "    result *= 26\n",
        "    result += ord(char) - ord('A') + 1\n",
        "  return result\n",
        "\n",
        "# Test cases\n",
        "print(get_excel_column_number('J'))   # Output: 10\n",
        "print(get_excel_column_number('AP'))  # Output: 42\n",
        "print(get_excel_column_number('AAA')) # Output: 703\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "10\n",
            "42\n",
            "703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFSrFUwP-zdd",
        "outputId": "812a2ccd-c092-4df5-ee99-8fa503773449",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check\n",
        "get_excel_column_number('BD')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZaQlyAc-zde",
        "outputId": "6235c36e-cb61-4a86-b8c4-9ae0b616842b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check\n",
        "get_excel_column_number('ALQ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1005"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh_MA_BN-zd5"
      },
      "source": [
        "# <u> Problem 2</u>\n",
        "\n",
        "### We evaluate a standard machine learning classification model using various evaluation metrics. A classification model is a model which classifies a given observation or an event to a fixed set of categories. Suppose I train a machine learning model to classify images of cats and dogs. For each image, the machine classifies the image with either a <code>'Cat'</code> or a <code>'Dog'</code>. So in essence for each input image, there is a corresponding output by the model. This output can either be a <code>'Cat'</code> or a <code>'Dog'</code>.\n",
        "\n",
        "### To evaluate such a machine learning model which is trained to classify a given observation with at most two labels, a lot of candidate evaluation metrics are available. Accuracy is one of such evaluation metrics.\n",
        "\n",
        "### <u> Accuracy defintion </u> : Suppose you are given 20 input images of cats and dogs. You already know from these images that there are 11 cats and 9 dogs. You train a machine learning model to classify these images into cats and dogs. The machine predicts 9 cats correctly and 8 dogs correctly. The accuracy of the model is then defined as (correctly predicted cats and dogs)/(total cats and dogs). In this case it is (9+8)/(11+9) = 17/20 = 0.85 or 85%. It is a good practice to report the accuracy in percentages\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp2SUazju_D7"
      },
      "source": [
        "### You are given two lists each of length 20 : one list contains the actual labels for the images of cats and dogs. The other list contains the predicted labels (by the machine) for the images of cats and dogs.\n",
        "\n",
        "### How to read the two lists ? For example for the first image, actual label is Cat and the predicted label is Cat. For the last image, actual label is Dog and the predicted label is Cat. The same index in the two lists corresponds to the same image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPsQbNPjvjAT"
      },
      "source": [
        "actual_labels = ['Cat','Dog','Cat','Cat','Dog','Cat','Dog','Cat','Cat','Cat','Dog','Dog','Cat','Cat','Cat','Dog','Dog','Dog','Cat','Dog']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDefeYf1v4pT"
      },
      "source": [
        "predicted_labels = ['Cat','Dog','Cat','Cat','Dog','Cat','Dog','Cat','Dog','Dog','Dog','Dog','Cat','Cat','Cat','Dog','Dog','Dog','Cat','Cat']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzLROuvWwZAL"
      },
      "source": [
        "### Write a function to calculate the accuracy. This functions takes two lists as inputs and returns the accuracy score in percentage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvDJXfL3-zd6"
      },
      "source": [
        "\n",
        "def calculate_accuracy(actual, predicted):\n",
        "    \"\"\"\n",
        "    This function calculates the accuracy based on two input lists.\n",
        "    \"\"\"\n",
        "    correct_predictions = sum(1 for act, pred in zip(actual, predicted) if act == pred)\n",
        "    total_predictions = len(actual)\n",
        "    accuracy = (correct_predictions / total_predictions) * 100\n",
        "    return accuracy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At0m0hcc-zd_",
        "outputId": "f0bf84c5-1a66-40a1-c30e-5d5da929ab81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Print the accuracy score for the given lists\n",
        "accuracy_score = calculate_accuracy(actual_labels, predicted_labels)\n",
        "print(\"Accuracy:\", accuracy_score, \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 85.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyYwXAlax36r"
      },
      "source": [
        "* ### <b><u>Precision</u></b> for cats is defined as the number of correctly predicted cats divided by the number of predicted cats. Report precision in percentages.\n",
        "\n",
        "* ### <b><u>Recall</u></b> for cats is defined as the number of correctly predicted cats divided by the actual number of cats. Report recall in percentages.\n",
        "\n",
        "### We can define the same two metrics for dogs as well.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwYIek-9yd4n"
      },
      "source": [
        "# <u> Problem 3 </u>\n",
        "\n",
        "### Write a Python function which returns the precision and recall for a given input label. Use the same two lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SojiZTMSyY4T",
        "outputId": "84c39a89-39c9-4128-fcc3-9c493adbba30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def precision_recall(actual, predicted, label='Dog'):\n",
        "    \"\"\"\n",
        "    This function returns a tuple of precision and recall for a given input label.\n",
        "    \"\"\"\n",
        "    true_positive = sum(1 for act, pred in zip(actual, predicted) if act == pred == label)\n",
        "    predicted_positive = sum(1 for pred in predicted if pred == label)\n",
        "    actual_positive = sum(1 for act in actual if act == label)\n",
        "\n",
        "    precision = true_positive / predicted_positive if predicted_positive != 0 else 0\n",
        "    recall = true_positive / actual_positive if actual_positive != 0 else 0\n",
        "\n",
        "    return precision, recall\n",
        "\n",
        "# Test the function with the provided lists\n",
        "actual_labels = ['Cat','Dog','Cat','Cat','Dog','Cat','Dog','Cat','Cat','Cat','Dog','Dog','Cat','Cat','Cat','Dog','Dog','Dog','Cat','Dog']\n",
        "predicted_labels = ['Cat','Dog','Cat','Cat','Dog','Cat','Dog','Cat','Dog','Dog','Dog','Dog','Cat','Cat','Cat','Dog','Dog','Dog','Cat','Cat']\n",
        "\n",
        "precision, recall = precision_recall(actual_labels, predicted_labels, label='Dog')\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.8\n",
            "Recall: 0.8888888888888888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-5eBWXa1Mla"
      },
      "source": [
        "# <u> Problem 4 </u>\n",
        "\n",
        "### Write a Python function which takes a sentence and a length value as inputs and returns the counts of those words from the sentence whose length is equal to the provided input length value.\n",
        "\n",
        "### Suppose if the input for the length value is 5, it will return the count of all those words which are of length 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ueu9nJx1uUZ"
      },
      "source": [
        "marvel_quote = \"The world has changed and none of us can go back. All we can do is our best, and sometimes the best that we can do is to start over.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OPAUOCT2VQW",
        "outputId": "953816cd-1713-419e-9dd0-5ae5722b79ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def fixed_length_word_counts(sentence, length=3):\n",
        "    \"\"\"\n",
        "    This function returns the count of the words with the given input length.\n",
        "    \"\"\"\n",
        "    # Remove punctuation marks\n",
        "    sentence = sentence.replace(',', '').replace('.', '')\n",
        "\n",
        "    # Split the sentence into words\n",
        "    words = sentence.split()\n",
        "\n",
        "    # Count words with the specified length\n",
        "    count = sum(1 for word in words if len(word) == length)\n",
        "\n",
        "    return count\n",
        "\n",
        "\n",
        "length = 5\n",
        "word_count = fixed_length_word_counts(marvel_quote, length)\n",
        "print(f\"Number of words with length {length}: {word_count}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words with length 5: 2\n"
          ]
        }
      ]
    }
  ]
}